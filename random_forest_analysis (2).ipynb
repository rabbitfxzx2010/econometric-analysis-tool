{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 Econometric Analysis Report\n",
        "## Generated by Quick Learning Analytics\n",
        "\n",
        "**Generated on:** 2025-09-11 20:45:43  \n",
        "**Method:** Random Forest  \n",
        "**Problem Type:** Regression  \n",
        "**Features:** 10  \n",
        "**Source:** Supervised Learning Tool by Ren Zhang, McCoy College of Business, Texas State University\n",
        "\n",
        "---\n",
        "\n",
        "This notebook replicates your exact analysis from the Quick Learning Analytics econometric app, including all preprocessing steps, model configuration, and evaluation metrics.\n",
        "\n",
        "**Visit:** [Quick Learning Analytics](https://quicklearninganalytics.streamlit.app/) for more information and tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ✅ Options Tracking Checklist\n",
        "\n",
        "This analysis tracks **ALL** the options you selected in the app:\n",
        "\n",
        "### 📊 **Basic Configuration**\n",
        "- ✅ **Method:** Random Forest\n",
        "- ✅ **Problem Type:** Regression\n",
        "- ✅ **Target Variable:** `age`\n",
        "- ✅ **Features:** 10 variables\n",
        "  - `high_earner`, `is_urban`, `education_PhD`, `experience`, `promotion`...\n",
        "- ✅ **Random State:** 42 (for reproducibility)\n",
        "\n",
        "### 🔧 **Data Processing Options**\n",
        "- ✅ **Data File:** test_dataset_classification.csv\n",
        "- ✅ **Missing Data:** KNN Imputation\n",
        "- ✅ **Data Filtering:** 1 filters applied\n",
        "- ❌ **Feature Scaling:** Disabled\n",
        "- ✅ **Sample Range:** Full dataset\n",
        "\n",
        "### 🤖 **Model-Specific Options**\n",
        "- ✅ **Max Depth:** 5\n",
        "- ✅ **Min Samples Split:** 2\n",
        "- ✅ **Min Samples Leaf:** 1\n",
        "- ✅ **Number of Trees:** 120\n",
        "- ✅ **Pruning:** Automatic (CV)\n",
        "- ❌ **Manual Alpha:** Auto\n",
        "\n",
        "### 📈 **Analysis Options**\n",
        "- ✅ **Include Constant:** Yes\n",
        "- ✅ **Test Size:** 0.2 (20% for testing)\n",
        "- ✅ **Generate Plots:** Enabled\n",
        "- ❌ **Stratified Split:** No\n",
        "\n",
        "### 🔍 **Advanced Options**\n",
        "- ❌ **Parameter Input Method:** Default\n",
        "- ✅ **Class Weight Option:** None\n",
        "- ✅ **Filter Method:** Column Values\n",
        "\n",
        "---\n",
        "\n",
        "💡 **All these options are replicated exactly in the code below!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your dataset\n",
        "df = pd.read_csv('test_dataset_classification.csv')\n",
        "\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "print(f'Columns: {list(df.columns)}')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔍 Data Filtering\n",
        "\n",
        "Applying the same filters you used in your analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply data filters (replicating your selections)\n",
        "# Filter 1: hours_worked between 27.4 and 51.43\n",
        "df = df[(df['hours_worked'] >= 27.4) & (df['hours_worked'] <= 51.43)]\n",
        "\n",
        "print(f'After filtering: {df.shape}')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Missing Data Handling\n",
        "\n",
        "Method: **KNN Imputation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle missing values using KNN imputation\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "df[numeric_cols] = knn_imputer.fit_transform(df[numeric_cols])\n",
        "print('✓ Applied KNN imputation to numeric columns')\n",
        "\n",
        "# Check for remaining missing values\n",
        "print(f'Missing values after imputation: {df.isnull().sum().sum()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Variable Definition and Preprocessing\n",
        "\n",
        "Defining features and target variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define variables (matching your analysis)\n",
        "independent_vars = ['high_earner', 'is_urban', 'education_PhD', 'experience', 'promotion', 'education_Bachelor', 'education_High School', 'education_Master', 'income', 'hours_worked']\n",
        "dependent_var = 'age'\n",
        "\n",
        "# Extract features and target\n",
        "X = df[independent_vars].copy()\n",
        "y = df[dependent_var].copy()\n",
        "\n",
        "# Define model type for visualization and logic\n",
        "model_type = 'regression'\n",
        "\n",
        "print(f'Feature matrix shape: {X.shape}')\n",
        "print(f'Target variable shape: {y.shape}')\n",
        "print(f'Features: {list(X.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤖 Model Training: Random Forest\n",
        "\n",
        "Training with your exact settings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f'Training set: {X_train.shape[0]} samples')\n",
        "print(f'Test set: {X_test.shape[0]} samples')\n",
        "\n",
        "# Random Forest Regression\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=120,\n",
        "    max_depth=5,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "print('✓ Model trained successfully')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📈 Model Evaluation\n",
        "\n",
        "Calculate performance metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Regression metrics\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print('🎯 KEY RESULTS (Should match main window):')\n",
        "print('='*60)\n",
        "print(f'📊 Training R²: {train_r2:.4f}')\n",
        "print(f'📊 Test R²: {test_r2:.4f}')\n",
        "print(f'📊 Training RMSE: {train_rmse:.4f}')\n",
        "print(f'📊 Test RMSE: {test_rmse:.4f}')\n",
        "print(f'📊 Training MAE: {train_mae:.4f}')\n",
        "print(f'📊 Test MAE: {test_mae:.4f}')\n",
        "print('='*60)\n",
        "\n",
        "print('\\n=== DETAILED MODEL PERFORMANCE ===')\n",
        "print(f'Training R²: {train_r2:.6f}')\n",
        "print(f'Test R²: {test_r2:.6f}')\n",
        "print(f'Training MSE: {train_mse:.6f}')\n",
        "print(f'Test MSE: {test_mse:.6f}')\n",
        "print(f'Training RMSE: {train_rmse:.6f}')\n",
        "print(f'Test RMSE: {test_rmse:.6f}')\n",
        "print(f'Training MAE: {train_mae:.6f}')\n",
        "print(f'Test MAE: {test_mae:.6f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔥 Feature Analysis\n",
        "\n",
        "Analyzing feature importance or coefficients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance analysis\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print('\\n🔥 FEATURE IMPORTANCE (Top features):')\n",
        "print('='*50)\n",
        "for idx, row in feature_importance.head().iterrows():\n",
        "    print(f'📈 {row[\"feature\"]:<25}: {row[\"importance\"]:.6f}')\n",
        "print('='*50)\n",
        "\n",
        "# Display complete feature importance\n",
        "feature_importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Visualization\n",
        "\n",
        "Generate comprehensive plots:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "# Regression plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('Random Forest - Regression Analysis Plots', fontsize=16)\n",
        "\n",
        "# 1. Actual vs Predicted\n",
        "axes[0, 0].scatter(y_test, y_test_pred, alpha=0.6)\n",
        "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "axes[0, 0].set_xlabel('Actual Values')\n",
        "axes[0, 0].set_ylabel('Predicted Values')\n",
        "axes[0, 0].set_title('Actual vs Predicted Values')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Residual plot\n",
        "residuals = y_test - y_test_pred\n",
        "axes[0, 1].scatter(y_test_pred, residuals, alpha=0.6)\n",
        "axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
        "axes[0, 1].set_xlabel('Predicted Values')\n",
        "axes[0, 1].set_ylabel('Residuals')\n",
        "axes[0, 1].set_title('Residual Plot')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Residual distribution\n",
        "axes[1, 0].hist(residuals, bins=20, alpha=0.7, edgecolor='black')\n",
        "axes[1, 0].set_xlabel('Residuals')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].set_title('Distribution of Residuals')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Q-Q plot for residuals\n",
        "from scipy import stats\n",
        "stats.probplot(residuals, dist='norm', plot=axes[1, 1])\n",
        "axes[1, 1].set_title('Q-Q Plot of Residuals')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "feature_importance_sorted = feature_importance.sort_values('importance', ascending=True)\n",
        "plt.barh(feature_importance_sorted['feature'], feature_importance_sorted['importance'])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Random Forest - Feature Importance')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Random Forest - Individual Tree Visualization\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Plot the first tree from the forest\n",
        "plt.figure(figsize=(20, 12))\n",
        "plot_tree(model.estimators_[0],\n",
        "          feature_names=X.columns,\n",
        "          class_names=None if model_type == 'regression' else True,\n",
        "          filled=True,\n",
        "          rounded=True,\n",
        "          fontsize=8)\n",
        "plt.title('Random Forest - Sample Tree (Tree #1 of {model.n_estimators})\\nRandom Forest', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Random Forest Tree Statistics\n",
        "print('\\n🌳 RANDOM FOREST PROPERTIES:')\n",
        "print('='*40)\n",
        "print(f'🔢 Number of Trees: {model.n_estimators}')\n",
        "print(f'🍃 Max Features per Tree: {model.max_features}')\n",
        "print(f'📏 Max Depth Setting: {model.max_depth}')\n",
        "print(f'🔀 Min Samples Split: {model.min_samples_split}')\n",
        "print(f'🍀 Min Samples Leaf: {model.min_samples_leaf}')\n",
        "print(f'🎲 Bootstrap Samples: {model.bootstrap}')\n",
        "print('='*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Analysis Summary\n",
        "\n",
        "✅ **Analysis completed successfully!**\n",
        "\n",
        "**Key Information:**\n",
        "- **Method:** Random Forest\n",
        "- **Problem Type:** Regression\n",
        "- **Features:** 10\n",
        "- **Preprocessing:** Applied\n",
        "- **Cross-validation:** No\n",
        "- **Plots:** Generated\n",
        "\n",
        "⚠️ **Important:** Compare the KEY RESULTS above with your main window to verify accuracy!\n",
        "\n",
        "🔄 **Reproducibility:** This notebook uses `random_state=42` for consistent results."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
